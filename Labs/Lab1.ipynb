{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lab 1\n",
    "## **Text processing**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 1:\n",
    "Benchmark different language-detection algorithm by computing accuracy of each approach.\n",
    "- FastText\n",
    "- LangID\n",
    "- langDetect\n",
    "\n",
    "Hint: use language code conversion `iso639-lang`\n",
    "\n",
    "Report\n",
    "- Accuracy\n",
    "- Average time per example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/MorenoLaQuatra/DeepNLP/main/practices/P1/langid_dataset.csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### My code.."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import\n",
    "import pandas as pd\n",
    "\n",
    "# read file\n",
    "corpus = pd.read_csv('langid_dataset.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sneak peak\n",
    "corpus.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# accuracy function and format printing-function\n",
    "\n",
    "def acc(clf_fcn, corpus):\n",
    "    correct = 0\n",
    "    for text,lan in zip(corpus.Text, corpus.language):\n",
    "        try:\n",
    "            pred = clf_fcn(text)\n",
    "            if type(pred) == tuple: # langid_classify returns lang and prob\n",
    "                pred = pred[0]\n",
    "        except:\n",
    "            continue\n",
    "        else:\n",
    "            correct += (pred == Lang(lan).pt1)*1\n",
    "    return correct\n",
    "\n",
    "def output(method, corpus, correct, elapsed):\n",
    "    print(f'{method:s} \\nAccuracy: {correct/len(corpus):.3f}. Est time/sample: {elapsed/len(corpus)*1000:.3f} ms')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "#!pip install iso639-lang\n",
    "from iso639 import Lang"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# FastText (fastlangid)\n",
    "from fastlangid import LID\n",
    "\n",
    "method = 'FastText'\n",
    "\n",
    "# fastText model\n",
    "fastText_clf = LID()\n",
    "\n",
    "# accuracy and timing\n",
    "start = time.time()\n",
    "correct = acc(fastText_clf.predict, corpus)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "# print result\n",
    "output('FastText', corpus, correct, elapsed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# LangID\n",
    "#!pip install langid\n",
    "import langid\n",
    "\n",
    "method = 'LangID'\n",
    "\n",
    "# accuracy and timing\n",
    "start = time.time()\n",
    "correct = acc(langid.classify, corpus)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "# print result\n",
    "output(method, corpus,correct, elapsed)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# langdetect\n",
    "#!pip install langdetect\n",
    "from langdetect import detect\n",
    "\n",
    "method = 'langdetect'\n",
    "\n",
    "# accuracy and timing\n",
    "start = time.time()\n",
    "correct = acc(detect, corpus)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "# print result\n",
    "output(method, corpus, correct, elapsed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 2\n",
    "For English-written text, apply word-level tokenization. What is the average number of words per sentence?\n",
    "Implement word-tokenization using both nltk and spacy. Report the results for both of them.\n",
    "For spaCy use the en_core_web_sm model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### My code..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# find only english texts\n",
    "corpus_eng = corpus.loc[corpus.language=='English']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# imports\n",
    "#!pip install nltk\n",
    "import nltk\n",
    "!pip install -U spacy\n",
    "#python -m spacy download en_core_web_sm (run in terminal)\n",
    "import spacy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# counting average number of words\n",
    "\n",
    "# nltk\n",
    "tot_words = 0\n",
    "for sentence in corpus_eng.Text:\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tot_words += len(tokens)\n",
    "\n",
    "print(f'NLTK \\nAverage number of words/sentence: {tot_words/len(corpus_eng):.2f}')\n",
    "\n",
    "# spacy\n",
    "spacy_nlp = spacy.load(\"en_core_web_sm\")\n",
    "tot_words = 0\n",
    "for sentence in corpus_eng.Text:\n",
    "    doc = spacy_nlp(sentence)\n",
    "    sentence_words = 0\n",
    "    sentence_words += sum([1 for w in doc]) #includes \"space\" and \" - \"\n",
    "    tot_words += sentence_words\n",
    "\n",
    "print(f'spaCy \\nAverage number of words/sentence: {tot_words/len(corpus_eng):.2f}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for w in doc:\n",
    "    print(w)\n",
    "\n",
    "n = 0\n",
    "a = sum([1 for w in doc])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
